{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf18304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic_ai\n",
    "from pydantic_ai.models import bedrock as bedrock_models\n",
    "\n",
    "claude_haiku = bedrock_models.BedrockConverseModel(\n",
    "    model_name=\"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    ")\n",
    "\n",
    "claude_sonnet = bedrock_models.BedrockConverseModel(\n",
    "    model_name=\"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    ")\n",
    "\n",
    "bedrock_model_settings = bedrock_models.BedrockModelSettings(\n",
    "    bedrock_guardrail_config={\"trace\": \"enabled\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19327fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pydantic_ai.messages import ModelMessage, ModelRequest, ModelResponse, TextPart, UserPromptPart\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentDependencies:\n",
    "    source_policy: str\n",
    "    messages: list[ModelMessage] = field(default_factory=list)\n",
    "\n",
    "\n",
    "common_tools = pydantic_ai.FunctionToolset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.trace import set_tracer_provider\n",
    "\n",
    "def setup_tracing():\n",
    "    if not os.getenv(\"OTEL_EXPORTER_OTLP_ENDPOINT\"):\n",
    "        return print(\"OTEL_EXPORTER_OTLP_ENDPOINT not set, skipping tracing setup\")\n",
    "\n",
    "    os.environ[\"OTEL_SERVICE_NAME\"] = \"managed-agent-swarm\"\n",
    "\n",
    "    exporter = OTLPSpanExporter()\n",
    "    span_processor = BatchSpanProcessor(exporter)\n",
    "    tracer_provider = TracerProvider()\n",
    "    tracer_provider.add_span_processor(span_processor)\n",
    "\n",
    "    set_tracer_provider(tracer_provider)\n",
    "\n",
    "setup_tracing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61c5eba",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    User[User] --> Orch[Orchestrator<br/>+ Message History]\n",
    "    \n",
    "    Orch <-->|ask/respond| Critique[Critique<br/>Agent]\n",
    "    Orch <-->|ask/respond| Gap[Gap<br/>Agent]\n",
    "    Orch <-->|ask/respond| Ambig[Ambiguity<br/>Agent]\n",
    "    \n",
    "    Orch ==>|handoff| Writer[Report<br/>Writer]\n",
    "    Writer --> Report[Final<br/>Report]\n",
    "    \n",
    "    style Orch fill:#e1f5ff,stroke:#0066cc,stroke-width:3px\n",
    "    style Writer fill:#e8f5e9,stroke:#4caf50,stroke-width:2px\n",
    "    style Report fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b26191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Final report model\n",
    "class FinalReport(BaseModel):\n",
    "    \"\"\"Final comprehensive report\"\"\"\n",
    "    executive_summary: str\n",
    "    key_findings: str\n",
    "    detailed_analysis: str\n",
    "    recommendations: str\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"FinalReport(\\n\"\n",
    "            f\"  Executive Summary: {self.executive_summary}\\n\"\n",
    "            f\"  Key Findings: {self.key_findings}\\n\"\n",
    "            f\"  Detailed Analysis: {self.detailed_analysis}\\n\"\n",
    "            f\"  Recommendations: {self.recommendations}\\n\"\n",
    "            f\")\"\n",
    "        )\n",
    "\n",
    "\n",
    "instrumentation_settings = pydantic_ai.InstrumentationSettings(\n",
    "    include_binary_content=False,\n",
    "    include_content=False,\n",
    ")\n",
    "\n",
    "critique_agent = pydantic_ai.Agent(\n",
    "    model=claude_haiku,\n",
    "    model_settings=bedrock_model_settings,\n",
    "    deps_type=AgentDependencies,\n",
    "    output_type=str,\n",
    "    system_prompt=\"\"\"You are a critique specialist that analyzes how farming policy documents are written.\n",
    "    Focus on clarity, structure, tone, accessibility, and communication effectiveness.\n",
    "    \n",
    "    IMPORTANT: You are part of an active group discussion. Review ALL previous messages carefully:\n",
    "    \n",
    "    When responding to questions:\n",
    "    - ALWAYS acknowledge and reference specific points made by other agents\n",
    "    - Build directly on their findings with your unique perspective\n",
    "    - Challenge or validate their observations explicitly\n",
    "    - Ask follow-up questions when you need clarity from them\n",
    "    - Point out connections between your analysis and theirs\n",
    "    \n",
    "    Examples:\n",
    "    - \"I agree with Gap Analysis Agent's point about X. The missing content creates structural issues because...\"\n",
    "    - \"Ambiguity Agent, you mentioned Y was unclear. I've noticed this also affects the document flow in section Z...\"\n",
    "    - \"Building on what Gap Analysis found, the lack of X makes the tone inconsistent when...\"\n",
    "    \n",
    "    Be conversational and engaged. This is a dialogue, not a report.\n",
    "    \n",
    "    Use all the tools at your disposal to reference the target policy document as needed.\"\"\",\n",
    "    instrument=instrumentation_settings,\n",
    "    toolsets=[common_tools],\n",
    ")\n",
    "\n",
    "gap_analysis_agent = pydantic_ai.Agent(\n",
    "    model=claude_haiku,\n",
    "    model_settings=bedrock_model_settings,\n",
    "    deps_type=AgentDependencies,\n",
    "    output_type=str,\n",
    "    system_prompt=\"\"\"You are a gap analysis specialist for farming policies.\n",
    "    Identify missing information, overlooked areas, and gaps in coverage.\n",
    "    Consider what's not addressed that should be for comprehensive policy.\n",
    "    \n",
    "    IMPORTANT: You are part of an active group discussion. Review ALL previous messages carefully:\n",
    "    \n",
    "    When responding to questions:\n",
    "    - ALWAYS reference specific observations from other agents\n",
    "    - Explain how gaps you find relate to issues they've raised\n",
    "    - Directly address their concerns with evidence from the policy\n",
    "    - Ask them for clarification or additional perspective\n",
    "    - Build collaborative understanding\n",
    "    \n",
    "    Examples:\n",
    "    - \"Critique Agent, your concern about structure is spot-on. The document is missing...\"\n",
    "    - \"Responding to Ambiguity Agent's point about vague language - I see the same pattern in missing definitions...\"\n",
    "    - \"This gap I found might explain why Critique Agent observed X. Can we explore that connection?\"\n",
    "    \n",
    "    Engage actively with the conversation. Reference others' names and specific points.\n",
    "    \n",
    "    Use all the tools at your disposal to reference the target policy document as needed.\"\"\",\n",
    "    instrument=instrumentation_settings,\n",
    "    toolsets=[common_tools],\n",
    ")\n",
    "\n",
    "ambiguity_agent = pydantic_ai.Agent(\n",
    "    model=claude_haiku,\n",
    "    model_settings=bedrock_model_settings,\n",
    "    deps_type=AgentDependencies,\n",
    "    output_type=str,\n",
    "    system_prompt=\"\"\"You are an ambiguity detection specialist.\n",
    "    Identify unclear language, vague requirements, and areas open to interpretation.\n",
    "    Highlight potential confusion points and suggest clarifications.\n",
    "    \n",
    "    IMPORTANT: You are part of an active group discussion. Review ALL previous messages carefully:\n",
    "    \n",
    "    When responding to questions:\n",
    "    - ALWAYS connect your findings to what other agents have said\n",
    "    - Explain how vague language might be causing the issues they identified\n",
    "    - Directly address their specific concerns\n",
    "    - Ask for their input on whether ambiguities explain their observations\n",
    "    - Create dialogue by referencing their names and points\n",
    "    \n",
    "    Examples:\n",
    "    - \"Gap Analysis Agent found X is missing. I wonder if that's because the language around it is so vague...\"\n",
    "    - \"Critique Agent, the structure issue you noted - could it stem from this ambiguous terminology?\"\n",
    "    - \"I agree with both of you. The vagueness I'm seeing in section Y connects to both the gaps and structure problems...\"\n",
    "    \n",
    "    Be conversational and collaborative. Make this a real discussion.\n",
    "    \n",
    "    Use all the tools at your disposal to reference the target policy document as needed.\"\"\",\n",
    "    instrument=instrumentation_settings,\n",
    "    toolsets=[common_tools],\n",
    ")\n",
    "\n",
    "report_writer_agent = pydantic_ai.Agent(\n",
    "    model=claude_sonnet,\n",
    "    model_settings=bedrock_model_settings,\n",
    "    deps_type=AgentDependencies,\n",
    "    output_type=str,\n",
    "    system_prompt=\"\"\"You are a report writing specialist.\n",
    "    Synthesize all the group discussion into a comprehensive, well-structured report.\n",
    "    Review the entire conversation history and create a cohesive analysis.\n",
    "    \n",
    "    Use all the tools at your disposal to reference the target policy document as needed.\"\"\",\n",
    "    instrument=instrumentation_settings,\n",
    "    toolsets=[common_tools],\n",
    ")\n",
    "\n",
    "\n",
    "# Output function for handoff to report writer\n",
    "async def handoff_to_report_writer(ctx: pydantic_ai.RunContext[AgentDependencies]) -> str:\n",
    "    \"\"\"Hand off to the report writer to synthesize all discussion into a final report.\n",
    "    Use this when the group discussion has produced sufficient insights.\"\"\"\n",
    "    \n",
    "    print(\"\\nüîÑ Handing off to Report Writer Agent...\")\n",
    "    \n",
    "    # Pass the conversation history to the report writer\n",
    "    response = await report_writer_agent.run(\n",
    "        user_prompt=\"Review the entire conversation history and create a comprehensive report synthesizing all findings.\",\n",
    "        deps=ctx.deps,\n",
    "        output_type=FinalReport,\n",
    "        message_history=ctx.deps.messages\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Report Writer completed\\n\")\n",
    "    return response.output\n",
    "\n",
    "\n",
    "# Orchestrator agent with tools to coordinate the group chat\n",
    "orchestrator_agent = pydantic_ai.Agent(\n",
    "    model=claude_haiku,\n",
    "    model_settings=bedrock_model_settings,\n",
    "    deps_type=AgentDependencies,\n",
    "    output_type=handoff_to_report_writer,\n",
    "    instrument=instrumentation_settings,\n",
    "    system_prompt=\"\"\"You are an orchestrator coordinating a group discussion about farming policy analysis.\n",
    "    \n",
    "    You have three specialist agents available:\n",
    "    - Critique Agent: analyzes how the document is written\n",
    "    - Gap Analysis Agent: identifies missing information and coverage gaps\n",
    "    - Ambiguity Agent: finds unclear or vague language\n",
    "    \n",
    "    Your role is to FACILITATE dialogue between the agents:\n",
    "    \n",
    "    1. Start by getting perspectives from the agents who are most relevant to the analysis\n",
    "    2. When an agent makes an observation, consider whether other agents should respond:\n",
    "       - Ask agents to build on each other's findings\n",
    "       - Direct follow-up questions when connections emerge\n",
    "       - Example: \"Ambiguity Agent, Critique Agent mentioned unclear structure. Does vague language contribute to this?\"\n",
    "    3. Create natural back-and-forth by having agents respond to each other's specific points\n",
    "    4. Push for concrete examples when agents make general observations\n",
    "    \n",
    "    IMPORTANT PRINCIPLES:\n",
    "    - ALWAYS include the agent's name in your question\n",
    "    - Reference specific points from other agents when creating dialogue\n",
    "    - Make agents talk TO each other, not just to you\n",
    "    - If an agent doesn't reference others, consider asking them to engage with prior observations\n",
    "    \n",
    "    When you feel the discussion has produced sufficient insights to answer the analysis comprehensively, hand off to the report writer. Don't force unnecessary rounds - quality over quantity.\"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "@orchestrator_agent.tool\n",
    "async def ask_critique_agent(ctx: pydantic_ai.RunContext[AgentDependencies], question: str) -> str:\n",
    "    \"\"\"Ask the critique agent to analyze how the document is written.\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìù Critique Agent: {question[:100]}...\")\n",
    "    \n",
    "    response = await critique_agent.run(\n",
    "        user_prompt=[\n",
    "            ctx.deps.source_policy,\n",
    "            question\n",
    "        ],\n",
    "        deps=ctx.deps,\n",
    "        message_history=ctx.deps.messages\n",
    "    )\n",
    "    \n",
    "    # Add to message history as a request/response pair\n",
    "    ctx.deps.messages.append(\n",
    "        ModelRequest(\n",
    "            parts=[UserPromptPart(content=f\"[Critique Agent] {question}\")],\n",
    "            timestamp=None\n",
    "        )\n",
    "    )\n",
    "\n",
    "    formatted = f\"[Critique Agent] {response.output}\"\n",
    "\n",
    "    ctx.deps.messages.append(\n",
    "        ModelResponse(\n",
    "            parts=[TextPart(content=formatted)],\n",
    "            timestamp=None\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Response received ({len(response.output)} chars)\\n\")\n",
    "    return formatted\n",
    "\n",
    "\n",
    "@orchestrator_agent.tool\n",
    "async def ask_gap_analysis_agent(ctx: pydantic_ai.RunContext[AgentDependencies], question: str) -> str:\n",
    "    \"\"\"Ask the gap analysis agent to identify missing information or coverage gaps.\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç Gap Analysis Agent: {question[:100]}...\")\n",
    "    \n",
    "    response = await gap_analysis_agent.run(\n",
    "        user_prompt=[\n",
    "            ctx.deps.source_policy,\n",
    "            question\n",
    "        ],\n",
    "        deps=ctx.deps,\n",
    "        message_history=ctx.deps.messages\n",
    "    )\n",
    "    \n",
    "    # Add to message history as a request/response pair\n",
    "    ctx.deps.messages.append(\n",
    "        ModelRequest(\n",
    "            parts=[UserPromptPart(content=f\"[Gap Analysis Agent] {question}\")],\n",
    "            timestamp=None\n",
    "        )\n",
    "    )\n",
    "\n",
    "    formatted = f\"[Gap Analysis Agent] {response.output}\"\n",
    "    \n",
    "    ctx.deps.messages.append(\n",
    "        ModelResponse(\n",
    "            parts=[TextPart(content=formatted)],\n",
    "            timestamp=None\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Response received ({len(response.output)} chars)\\n\")\n",
    "    return formatted\n",
    "\n",
    "\n",
    "@orchestrator_agent.tool\n",
    "async def ask_ambiguity_agent(ctx: pydantic_ai.RunContext[AgentDependencies], question: str) -> str:\n",
    "    \"\"\"Ask the ambiguity agent to identify unclear or vague language.\"\"\"\n",
    "    \n",
    "    print(f\"\\n‚ùì Ambiguity Agent: {question[:100]}...\")\n",
    "    \n",
    "    response = await ambiguity_agent.run(\n",
    "        user_prompt=[\n",
    "            ctx.deps.source_policy,\n",
    "            question\n",
    "        ],\n",
    "        deps=ctx.deps,\n",
    "        message_history=ctx.deps.messages\n",
    "    )\n",
    "\n",
    "    # Add to message history as a request/response pair\n",
    "    ctx.deps.messages.append(\n",
    "        ModelRequest(\n",
    "            parts=[UserPromptPart(content=f\"[Ambiguity Agent] {question}\")],\n",
    "            timestamp=None\n",
    "        )\n",
    "    )\n",
    "\n",
    "    formatted = f\"[Ambiguity Agent] {response.output}\"\n",
    "    \n",
    "    ctx.deps.messages.append(\n",
    "        ModelResponse(\n",
    "            parts=[TextPart(content=formatted)],\n",
    "            timestamp=None\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Response received ({len(response.output)} chars)\\n\")\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b77fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "policy_name = \"AGF1\"\n",
    "policy_path = pathlib.Path(f\"../scrapers/outputs/{policy_name.upper()}.md\")\n",
    "\n",
    "# Initialize dependencies\n",
    "deps = AgentDependencies(\n",
    "    source_policy=policy_path.read_text()\n",
    ")\n",
    "\n",
    "# Run the orchestrator to coordinate the group chat\n",
    "orchestrator_response = await orchestrator_agent.run(\n",
    "    user_prompt=[\n",
    "        \"\"\"Facilitate a group discussion to comprehensively analyze this farming policy document.\n",
    "    Let the agents respond to each other's findings and build on the discussion.\n",
    "    When you've gathered sufficient insights (aim for thorough coverage), generate the final report.\"\"\",\n",
    "    deps.source_policy\n",
    "    ],\n",
    "    deps=deps,\n",
    "    usage_limits=pydantic_ai.UsageLimits(tool_calls_limit=25)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# View the orchestrator's final response\n",
    "report: FinalReport = orchestrator_response.output\n",
    "\n",
    "pprint.pprint(report)\n",
    "\n",
    "# print (deps.messages)\n",
    "\n",
    "# print(f\"Total messages: {len(orchestrator_response.all_messages())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8309f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: View the complete message history and tool calls\n",
    "print(\"=== COMPLETE MESSAGE TRACE ===\\n\")\n",
    "pprint.pprint(str(orchestrator_response.all_messages_json()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-spike-agent-swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
