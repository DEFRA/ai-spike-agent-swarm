{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import bs4\n",
    "import httpx\n",
    "\n",
    "fund_base_url = \"https://www.gov.uk/find-funding-for-land-or-farms\"\n",
    "\n",
    "\n",
    "def extract_fund_links(html_content):\n",
    "    results = html_content.find(\"div\", id=\"js-results\")\n",
    "\n",
    "    actions = results.find_all(\"a\", {\"class\": \"govuk-link\"})\n",
    "\n",
    "    links = []\n",
    "\n",
    "    for action in actions:\n",
    "        link = action.get(\"href\")\n",
    "\n",
    "        links.append(link)\n",
    "\n",
    "    return links\n",
    "\n",
    "\n",
    "def extract_fund_code(link):\n",
    "    parts = link.split(\"/\")[-1].split(\"-\")\n",
    "\n",
    "    return parts[0].upper()\n",
    "\n",
    "\n",
    "async def get_funds(page_num):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(f\"{fund_base_url}?page={page_num}\")\n",
    "\n",
    "        soup = bs4.BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "        return [\n",
    "            {\"code\": extract_fund_code(link), \"link\": link}\n",
    "            for link in extract_fund_links(soup)\n",
    "        ]\n",
    "\n",
    "\n",
    "tasks = await asyncio.gather(*[get_funds(page_num) for page_num in range(1, 6)])\n",
    "\n",
    "funds = []\n",
    "\n",
    "for task in tasks:\n",
    "    for fund in task:\n",
    "        funds.append(fund)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdownify import markdownify as md\n",
    "\n",
    "content_api_base_url = \"https://www.gov.uk/api/content\"\n",
    "\n",
    "\n",
    "async def add_fund_content(fund):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(f\"{content_api_base_url}{fund['link']}\")\n",
    "\n",
    "        html = response.json()[\"details\"][\"body\"]\n",
    "\n",
    "        soup = bs4.BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "        return md(str(soup), heading_style=\"ATX\")\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "batches = [funds[i : i + batch_size] for i in range(0, len(funds), batch_size)]\n",
    "\n",
    "for i in range(len(batches)):\n",
    "    batch = batches[i]\n",
    "\n",
    "    contents = await asyncio.gather(*[add_fund_content(fund) for fund in batch])\n",
    "\n",
    "    for fund, content in zip(batch, contents, strict=True):\n",
    "        fund[\"content\"] = content\n",
    "\n",
    "    print(f\"Completed batch {i + 1} out of {len(batches)}\")\n",
    "\n",
    "    await asyncio.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ffb850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import aiofiles\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "async def save_fund(fund):\n",
    "    filename = f\"{fund['code']}.md\"\n",
    "    filepath = output_dir / filename\n",
    "\n",
    "    async with aiofiles.open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        await f.write(fund[\"content\"])\n",
    "\n",
    "\n",
    "await asyncio.gather(*[save_fund(fund) for fund in funds])\n",
    "\n",
    "print(f\"\\nAll {len(funds)} markdown files saved to {output_dir.absolute()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-spike-agent-swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
